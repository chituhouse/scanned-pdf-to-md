# 扫描PDF转结构化文档 - 方法论指南

> 版本：1.0
> 创建日期：2026-01-11
> 商业模式：付费服务（面向个人/小团队客户）

---

## 一、适用场景

### 1.1 核心场景

| 场景 | 典型需求 | 复杂度 |
|:---|:---|:---|
| **历年真题PDF转题库** | 培训机构、考试辅导 | 高（结构复杂） |
| **扫描合同/协议数字化** | 律所、企业法务 | 中（格式固定） |
| **表格类文档结构化** | 财务报表、统计表格 | 高（表格识别难） |
| **书籍/教材数字化** | 出版社、个人收藏 | 中（页数多） |

### 1.2 不适用场景

- 手写文档（需要手写识别专用引擎）
- 极度模糊/低质量扫描件
- 纯图片内容（无文字）
- 需要100%完美准确率的法律文件（仍需人工校对）

---

## 二、核心方法论

### 2.1 双源互补架构

**为什么需要双源？**

单一OCR引擎存在固有缺陷：

| OCR类型 | 优势 | 劣势 |
|:---|:---|:---|
| 通用OCR | 文字完整度高、题号识别稳定 | 表格结构差、选项可能连成一行 |
| 智能文档解析 | 表格识别优秀、选项换行准确 | 可能漏识部分文字 |

**核心洞察**：两个OCR源的错误通常不会出现在同一位置。

**错误互补原理**：

```
纯OCR版：   A.xxx  B.xxx  C.xxx  [D缺失]
文档解析版：A.xxx  B.xxx  C.xxx  D.yyy

合并结果：  A.xxx  B.xxx  C.xxx  D.yyy  ✓
```

**如何选择OCR引擎组合？**

| 组合类型 | 推荐引擎 | 适用场景 |
|:---|:---|:---|
| 火山引擎组合 | 通用OCR + 智能文档解析 | 国内文档、中文为主 |
| 混合平台 | 百度OCR + 腾讯文档解析 | 需要多样性 |
| 国际组合 | Google Vision + AWS Textract | 英文文档 |

### 2.2 逐批处理模式

**为什么不能批量处理？**

实践教训：项目初期尝试批量处理20套题，发现后期套题格式问题明显增多。

| 批次大小 | 问题 | 表现 |
|:---|:---|:---|
| 1套/次 | 无 | 质量稳定 |
| 5套/次 | 轻微 | 后2套格式偶有问题 |
| 10套/次 | 明显 | 后3套需要返工 |
| 20套/次 | 严重 | 后8套格式混乱 |

**原因分析**：AI处理大批量数据时会产生"疲劳"，上下文过长导致注意力分散。

**最佳批次大小**：1套/次（质量最优）或 3套/次（效率与质量平衡）

**质量控制节点**：

```
处理1套 → 生成报告 → 人工确认 → 继续下一套
         ↑                        |
         └────────────────────────┘
```

### 2.3 交叉验证流程

**分割策略**：

```python
# 按年份月份识别边界
pattern = r'(20\d{2})\s*年\s*(\d+)\s*月.*?(?:真题|试卷|考试)'

# 分割为独立单元
units = [
    "2025年6月统考真题",
    "2025年6月答案解析",
    "2025年3月统考真题",
    # ...
]
```

**合并规则**：

| 内容类型 | 优先采用 | 原因 |
|:---|:---|:---|
| 表格 | 文档解析版 | Markdown格式更好 |
| 选项文本 | 文档解析版 | 换行更准确 |
| 题目文本 | 对比取更完整的 | 两版各有优劣 |
| 题号 | 纯OCR版 | 识别更稳定 |

**冲突处理**：

```markdown
# 当两版内容明显不一致时
[待人工确认：版本A为xxx，版本B为yyy]
```

### 2.4 铁律原则

**三不原则**：

| 铁律 | 说明 | 示例 |
|:---|:---|:---|
| **不发挥** | 只使用源文档中已有的内容 | 不添加"根据题意可知" |
| **不编造** | 缺失内容标注`[缺失]` | 不猜测答案是A还是B |
| **不修改** | 只修复格式，不改动文字 | 不把"蛋白质"改成"蛋白" |

**缺失标注规范**：

```markdown
# 选项缺失
D. [选项D缺失]

# 整题缺失
[第25题缺失]

# 答案缺失
25. 【答案】[缺失]
```

**人工复核节点**：

1. 每套题处理完毕后 → 展示验证报告 → 人工确认
2. 发现待确认项 → 人工判断 → 决定采用哪个版本
3. 最终交付前 → 人工抽检10% → 验收确认

---

## 三、技术实现

### 3.1 工具链

```
┌─────────────────────────────────────────────────────────────┐
│                     完整工具链                               │
├─────────────────────────────────────────────────────────────┤
│  Step 1: PDF转图片                                          │
│  - 工具: pdf2image / PyMuPDF                                │
│  - 输出: PNG图片（建议300dpi）                               │
├─────────────────────────────────────────────────────────────┤
│  Step 2: 双路OCR                                            │
│  - 路径A: 火山引擎通用OCR API                                │
│  - 路径B: 火山引擎智能文档解析API                            │
│  - 输出: 两份MD文档                                         │
├─────────────────────────────────────────────────────────────┤
│  Step 3: 交叉验证                                           │
│  - 工具: Claude Code + Custom Skill                         │
│  - 输入: 两份MD文档                                         │
│  - 输出: 验证版MD文档                                       │
├─────────────────────────────────────────────────────────────┤
│  Step 4: 格式转换                                           │
│  - Markdown → Word (python-docx)                            │
│  - Markdown → JSON (自定义脚本)                              │
│  - Markdown → PDF (pandoc)                                  │
└─────────────────────────────────────────────────────────────┘
```

### 3.2 API成本估算

**火山引擎定价**（2026年1月）：

| 服务 | 定价 | 示例 |
|:---|:---|:---|
| 通用OCR | 约 ¥0.01/次 | 371页 = ¥3.71 |
| 智能文档解析 | 约 ¥0.02/次 | 371页 = ¥7.42 |
| **合计** | - | 371页 ≈ ¥11.13 |

**Claude API成本**（逐套处理）：

| 模型 | 定价 | 每套估算 |
|:---|:---|:---|
| Claude Sonnet | $3/M input, $15/M output | 约 ¥0.5-1/套 |
| Claude Opus | $15/M input, $75/M output | 约 ¥2-5/套 |

**总成本估算**（371页PDF，20套题）：

| 项目 | 成本 |
|:---|:---|
| OCR API | ¥11.13 |
| Claude API | ¥10-20 |
| **合计** | ¥21-31 |

**批量优化策略**：

1. 使用 Sonnet 而非 Opus（成本降低5倍）
2. 逐套处理减少token浪费
3. 缓存OCR结果，避免重复调用

### 3.3 人工介入点

**必须人工的环节**：

| 环节 | 人工任务 | 预估时间 |
|:---|:---|:---|
| 套题确认 | 每套处理后确认验证报告 | 2-3分钟/套 |
| 冲突解决 | 处理"待人工确认"项 | 1-2分钟/项 |
| 最终校对 | 抽检10%内容 | 10-15分钟/项目 |

**可自动化的环节**：

- PDF转图片
- 双路OCR调用
- 格式标准化
- 干扰内容清除
- 文件合并

---

## 四、商业化实施（付费服务模式）

### 4.1 服务定价模型

**基础定价**：

| 文档类型 | 单价 | 说明 |
|:---|:---|:---|
| 简单文档（纯文字） | ¥0.5/页 | 无表格、格式简单 |
| 中等文档（含表格） | ¥1/页 | 有表格、选择题 |
| 复杂文档（试题类） | ¥1.5-2/页 | 多选项、多表格 |

**项目定价**：

| 项目类型 | 包价 | 包含 |
|:---|:---|:---|
| 单套真题（20页） | ¥50-80 | OCR+验证+交付 |
| 整本资料（100-200页） | ¥200-300 | 同上 |
| 大型项目（500页+） | 面议 | 定制报价 |

**附加费用**：

| 服务 | 加价 | 说明 |
|:---|:---|:---|
| 加急（24小时内） | +50% | 优先处理 |
| 人工精校 | +30% | 100%人工校对 |
| 多格式输出 | +¥20/格式 | 额外输出Word/JSON |

### 4.2 交付标准

**准确率承诺**：

| 等级 | 准确率 | 价格档 |
|:---|:---|:---|
| 标准版 | ≥90% | 基础价 |
| 精校版 | ≥95% | 基础价+30% |
| 完美版 | ≥99% | 基础价+100% |

**格式规范**：

```markdown
# 选项格式
A. 选项内容（字母+点+空格+内容）

# 答案格式
1. 【答案】A

# 括号规范
使用中文括号（）
```

**验收流程**：

1. 交付初稿 → 客户抽检10%
2. 发现问题 → 免费修正
3. 二次交付 → 客户确认
4. 验收通过 → 项目完成

### 4.3 成本控制

**成本结构**（以100页项目为例）：

| 项目 | 成本 | 占比 |
|:---|:---|:---|
| OCR API | ¥3 | 3% |
| Claude API | ¥5-10 | 5-10% |
| 人工时间（1小时） | ¥50-100 | 50-70% |
| 其他 | ¥10 | 10% |
| **合计** | ¥68-123 | - |

**定价建议**：成本×2-3 = 售价

100页项目：成本¥100 → 售价¥200-300

### 4.4 服务流程 SOP

```
1. 接单
   ├── 收到客户需求
   ├── 评估页数和复杂度
   └── 报价确认

2. 收PDF
   ├── 客户提供PDF文件
   ├── 检查文件质量
   └── 确认处理范围

3. 双路OCR
   ├── PDF转PNG图片
   ├── 火山引擎通用OCR
   └── 火山引擎文档解析

4. 交叉验证
   ├── Claude Code处理
   ├── 逐套验证确认
   └── 生成验证报告

5. 人工复核
   ├── 处理待确认项
   ├── 格式最终检查
   └── 质量抽检

6. 交付
   ├── 输出MD/Word/JSON
   ├── 发送给客户
   └── 等待反馈

7. 验收
   ├── 客户抽检确认
   ├── 问题修正（如有）
   └── 项目完成
```

### 4.5 客户获取渠道

**线上平台**：

| 平台 | 适合场景 | 获客成本 |
|:---|:---|:---|
| 猪八戒/一品威客 | 企业客户 | 低（平台抽成） |
| 淘宝/闲鱼 | 个人客户 | 低 |
| 小红书 | 教育类客户 | 中（需要内容） |
| 知乎 | 专业类客户 | 中 |

**线下渠道**：

- 培训机构合作
- 考试辅导班推荐
- 教育公司外包

**内容营销**：

- 发布方法论文章（本文档）
- 分享案例成果
- 开源基础工具

---

## 五、试错经验总结

### 5.1 踩过的坑

| 问题 | 原因 | 解决方案 | 教训 |
|:---|:---|:---|:---|
| 后期套题格式混乱 | 批量处理20套 | 改为逐套处理 | **不要贪多** |
| 水印混入正文 | 未建立干扰清单 | 维护干扰词列表 | **预先规划** |
| 选项格式不统一 | 未定义标准 | 增加格式化步骤 | **标准先行** |
| 内容顺序错乱 | 边界识别错误 | grep定位行号 | **精确定位** |
| AI编造内容 | 指令不够严格 | 增加铁律约束 | **约束AI** |

### 5.2 成功因素

1. **双源互补 > 单源优化**
   - 不要试图找"完美"的OCR引擎
   - 组合使用，取长补短

2. **逐套处理 > 批量处理**
   - 质量优先于速度
   - 每套确认，问题可追溯

3. **铁律原则 > 让AI自由发挥**
   - 明确约束，防止编造
   - 缺失标注，不要猜测

4. **验证报告 > 黑盒处理**
   - 透明记录所有操作
   - 便于人工复核

---

## 六、扩展方向

### 6.1 技术扩展

- 支持更多OCR服务（百度、腾讯、阿里）
- 增加手写识别能力
- 多语言支持

### 6.2 产品扩展

- Web界面（SaaS化）
- API服务（开放给开发者）
- 批量处理工具

### 6.3 场景扩展

- 合同文档数字化
- 发票/票据识别
- 书籍扫描数字化

---

## 附录A：Skill 快速启动

在 Claude Code 中输入：

```
/cross-validate-ocr
```

系统会自动：
1. 读取两个MD文件
2. 识别所有套题
3. 逐套交叉验证
4. 生成验证报告
5. 合并最终文档

---

## 附录B：常见问题

**Q: 为什么不直接用更好的OCR引擎？**

A: 没有"完美"的OCR引擎。不同引擎在不同内容上各有优劣，交叉验证是目前最可靠的提升准确率方案。

**Q: 处理非试题类文档可以吗？**

A: 可以。需要修改 Skill 文件中的分割规则和验证逻辑。

**Q: 为什么要用Claude Code而不是纯Python？**

A: 交叉验证需要理解语义、判断内容完整性、处理边界情况。这些任务LLM比硬编码规则更灵活准确。

**Q: 成本太高怎么办？**

A: 使用 Claude Sonnet 替代 Opus，成本可降低5倍。逐套处理也能有效控制token消耗。

---

*文档版本：1.0*
*创建日期：2026-01-11*
*适用场景：付费服务、个人/小团队客户*
*作者：PDF_OCR_json项目组*

---

*Made with Claude Code*
